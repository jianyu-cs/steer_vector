{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b3bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import Trace\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "# get the steering vector\n",
    "layer_id = 5\n",
    "#module = model.layers[layer_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a7f3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the activation steering hook\n",
    "def act_add(steering_vec):\n",
    "    def hook(module, input, output):\n",
    "        #print(len(output))\n",
    "        #print(output[0][0][0].shape)\n",
    "        #print(len(output[0]))\n",
    "        output[0][0][-1] += steering_vec\n",
    "        return output\n",
    "    return hook\n",
    "\n",
    "# define a hook function that caches activations\n",
    "def cache_hook(cache):\n",
    "\tdef hook(module, input, output):\n",
    "\t\tcache.append(output)\n",
    "\treturn hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3db33ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_layer_wrapper:\n",
    "    def __init__(self, model='gpt2', device=0):\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model,\n",
    "            pad_token=\"[PAD]\",\n",
    "            padding_side='left')\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model).to(self.device)\n",
    "        #self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        self.model_name = model\n",
    "         \n",
    "    def get_layer_next_output(self, layer_index):\n",
    "        if 'llama' in self.model_name:\n",
    "            return self.model.model.layers[layer_index]\n",
    "        elif 'gpt2' in self.model_name:\n",
    "            return self.model.transformer.h[layer_index]\n",
    "        elif 'opt' in self.model_name:\n",
    "            return self.model.model.decoder.layers[layer_index]\n",
    "        \n",
    "    def get_activation(self, input_string, layer_index):\n",
    "        module = self.get_layer_next_output(layer_index)\n",
    "        cache = []\n",
    "        handle = module.register_forward_hook(cache_hook(cache))\n",
    "        #with Trace(module) as ret:\n",
    "        #    _ = self.model(torch.tensor(self.tokenizer.encode(input_string)).unsqueeze(0).to(self.device))\n",
    "        #    answer = ret.output\n",
    "        _ = self.model(torch.tensor(self.tokenizer.encode(input_string)).unsqueeze(0).to(self.device))\n",
    "        result = cache[0]\n",
    "        handle.remove()\n",
    "        return result\n",
    "    \n",
    "    def generate_with_steering(self, test_inputs, layer_index, steering_vec):\n",
    "        module = self.get_layer_next_output(layer_index)\n",
    "        cache = []\n",
    "        handle = module.register_forward_hook(act_add(steering_vec))\n",
    "        #with Trace(module, edit_output=act_add(steering_vec)) as _:\n",
    "        test_encoding = self.tokenizer(test_inputs, padding=True, return_tensors = 'pt').to(self.device)\n",
    "        sample_outputs = self.model.generate(**test_encoding, pad_token_id=self.tokenizer.pad_token_id,do_sample=True, max_new_tokens=20, top_k=10, num_return_sequences=1)\n",
    "        ans = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)\n",
    "        handle.remove() \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df3d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename = '/data/jianyu/secretlanguage/rl-prompt/examples/steer_vector/tst_paired_50.jsonl'\n",
    "with open(filename, \"r\") as f:\n",
    "    data_sentiment = list(f)#json.load(f)\n",
    "data_sentiment = [json.loads(_) for _ in data_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d99ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_sentences = []\n",
    "pos_sentences = []\n",
    "neg_sentences = []\n",
    "for element in data_sentiment:\n",
    "    whole_sentences.append(element['neg'])\n",
    "    neg_sentences.append(element['neg'])\n",
    "    \n",
    "    pos_sentences.append(element['pos'])\n",
    "    whole_sentences.append(element['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "33d499a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = model_layer_wrapper('gpt2', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e6f968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_form(template):\n",
    "    return f\"\\\"{template}\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "132d3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = model.get_activation(whole_sentences[0], 7)[0][0, -1,:] - model.get_activation(whole_sentences[1], 7)[0][0, -1,:] #[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "44e3544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = model.get_activation(whole_sentences[2], 7)[0][0, -1,:] - model.get_activation(whole_sentences[3], 7)[0][0, -1,:] #[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9ac5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = model.get_activation(whole_sentences[4], 7)[0][0, -1,:] - model.get_activation(whole_sentences[5], 7)[0][0, -1,:] #[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "70a50efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = model.get_activation(whole_sentences[6], 7)[0][0, -1,:] - model.get_activation(whole_sentences[7], 7)[0][0, -1,:] #[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f677d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3588], device='cuda:3', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos(temp0.unsqueeze(0), temp1.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f8e2c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3312], device='cuda:3', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(temp0.unsqueeze(0), temp2.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a45d89a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (act): NewGELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.transformer.h[0]#(whole_sentences[1]).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9692fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 15, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_activation(whole_sentences[0], 8)[1][0][0].shape#[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18044eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.tokenizer.tokenize(whole_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f06cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_vector_calculate(model, input_string_pairs, layer_index):\n",
    "    # [a, b]\n",
    "    vec0 = model.get_activation(input_string_pairs[0], layer_index)[0][0, -1,:]\n",
    "    vec1 = model.get_activation(input_string_pairs[1], layer_index)[0][0, -1,:]\n",
    "    \n",
    "    return vec0, vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "828ac3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "vec1s = []\n",
    "vec0s = []\n",
    "for i in range(len(neg_sentences)):\n",
    "    vec0, vec1 = steering_vector_calculate(model, [neg_sentences[i], pos_sentences[i]], 7)\n",
    "    vec0s.append(vec0)\n",
    "    vec1s.append(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b08e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vec = torch.mean(torch.stack(vec1s), 0) - torch.mean(torch.stack(vec0s), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7aa7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2701ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(len(vecs)):\n",
    "    for j in range(i+1, len(vecs)):\n",
    "        final.append(cos(vecs[i].unsqueeze(0), vecs[j].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2c47f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "126deb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING = \"1\"\n",
    "elements = []\n",
    "for _ in range(32):\n",
    "    elements.append(model.generate_with_steering(neg_sentences[11], 7, 1.2*final_vec)[0].replace(\"\\\"\"+neg_sentences[11]+\"\\\" \\\"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1143be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you won't find a better selection in scottsdale.\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sentences[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "343d51ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"the charge did include miso soup and a small salad.\\n\\nThe couple is now planning an evening of food and drinks with the mayor's daughter, daughter\",\n",
       " 'the charge did include miso soup and a small salad. I also enjoyed the grilled chicken, and there was a nice little bit of a cheese dip on the',\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"It was very pleasant. We were talking for a short while about this and the future',\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"The whole thing was just kind of fun,\" he said.',\n",
       " 'the charge did include miso soup and a small salad. The meal was good enough for me. It was a good meal too and it also included some other',\n",
       " \"the charge did include miso soup and a small salad. It's not like we're the only ones who are eating at a restaurant with the idea of having\",\n",
       " 'the charge did include miso soup and a small salad.\\n\\nIt was not a very big affair.\\n\\nThe food was delicious, especially in the',\n",
       " 'the charge did include miso soup and a small salad. He also added he had a lot to say about his new job and about his family history.\\n',\n",
       " 'the charge did include miso soup and a small salad. She was also happy to talk about her love of her son, who is now 4 and who is',\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"The kids had good memories of being in the school, the teachers and the staff and',\n",
       " 'the charge did include miso soup and a small salad. I would have had a great meal at the bar.\\n\\nThe place was pretty good. You',\n",
       " 'the charge did include miso soup and a small salad.',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nHe added: \"There was a lot more to be said about this.\"',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nIn a statement, the company said that the restaurant was closed on Friday and would be open',\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"I\\'m really glad he came to work. We had a good time. He was',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nThe police also said the man was a resident of the village.\\n\\nThe man was',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nAfter lunch, the two men took their seats.\\n\\nKamil, who has',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nBut it\\'s also possible the chef is trying to make a good impression.\\n\\n\"',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nThe man, who has not been named, did not appear before the court.',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nIn the past, the restaurant has served up its own signature dish. But that has been',\n",
       " 'the charge did include miso soup and a small salad.',\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"We were just happy and proud of how well we did,\" he said. \"I',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nThe family of the dead soldier said it would like the police to investigate.\\n\\n\"',\n",
       " 'the charge did include miso soup and a small salad. The only other item on my menu included a side of rice that is made from fresh herbs.\\n',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nThe charge is $25 to $25 an hour for all adults over the age of 21',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nThe restaurant is located in a small town in the heart of the Bay Area. Its menu',\n",
       " 'the charge did include miso soup and a small salad. The menu was a little different, but they were very friendly and accommodating.\\n\\n\"They really',\n",
       " 'the charge did include miso soup and a small salad.\\n\\nBut the police chief said that when asked about that, the chief replied, \"No,',\n",
       " 'the charge did include miso soup and a small salad.',\n",
       " \"the charge did include miso soup and a small salad. I'm pretty sure there's nothing like a meal that has a healthy side. It's also worth\",\n",
       " \"the charge did include miso soup and a small salad. It's a good way to keep in touch, especially when you're getting back from vacation.\\n\",\n",
       " 'the charge did include miso soup and a small salad.\\n\\n\"They didn\\'t just come up with the idea. It had been done in a very']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d35f7a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am just making the point that you'll always have the perfect place, and I'm sure you\",\n",
       " 'You have no problems with that.\" \"I know what you mean,\" says the woman who runs the',\n",
       " \"The best thing about the town is that you're not a scotch or a kid with no\",\n",
       " 'There are plenty of scotties there, too.\"\\n\\nThe two of them, with their',\n",
       " 'It is also easy to spot the best students in the city in any given year.\"\\n\\n\"',\n",
       " 'The best are the ones that get to the point where they don\\'t need you.\"\\n\\n\"',\n",
       " \"You'll find a great place for a family to live as well as a business with a good location\",\n",
       " 'A lot of them are just good people, but not as good as some of the kids in my',\n",
       " 'You\\'re not wrong.\" \"The kids are doing a great job.\" \"I\\'ve seen a lot',\n",
       " 'You\\'ll just be able to have a great deal of conversation with the locals.\"\\n\\nAs the',\n",
       " 'You will find a few that are easy to keep in the house.\"\\n\\nI am the most',\n",
       " 'I\\'m sure you\\'ll find a lot of people who can get you all the way in,\" says',\n",
       " \"You'll be able to find any number of the things we've got going, including the fact that\",\n",
       " \"The city has made its way all through the park, and it's hard to get lost in its\",\n",
       " \"I think that's a big deal because I have the perfect family, they're all nice and they\",\n",
       " 'You\\'ll also get a lot of things from my house, too.\" \"I\\'m always there.\"',\n",
       " 'I can also say, the other day, you won the same price of the most expensive thing for',\n",
       " 'If you can make it easy for others, there\\'s no downside to being an early winner.\"\\n',\n",
       " 'And it was the perfect time to go home.\" If I\\'m going to be a bit of a',\n",
       " \"We have the same size and are in the same city, and we've got some great things to\",\n",
       " 'I\\'ve got lots of things you\\'ll find in the store.\" (This will be an easy way',\n",
       " \"If I were to take this question as being the only one I'm looking at as having a strong\",\n",
       " 'If you\\'re able to find a few, then you have the most fun.\" And that\\'s all',\n",
       " 'In fact, it has been the most popular and successful place to get the kids who are the most',\n",
       " \"You'll have a great deal of work in the market of all of the people who are able to\",\n",
       " 'If you find your children are happy with their jobs and have good relationships,\" says D\\'Angelo,',\n",
       " 'There\\'s no need to say this about your children.\"',\n",
       " 'And you\\'ll have the same results as you can find any time.\" \"I can find the same',\n",
       " 'You\\'ll get the job, too.\" \"I\\'ll get you a job as a clerk,\" and',\n",
       " \"And if there are no bad people in the city, they're just as good with the same age\",\n",
       " \"There's no way you won't find a better list of places and prices in the city of Sc\",\n",
       " 'It is hard to say that the school is not a place where people are looking for work,\" said']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895dc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7d9cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ever since joes has changed hands it's gotten better and better.\",\n",
       " 'there is so much room in that part of the venue.',\n",
       " \"it didn't taste watered down at all.\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fe6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
